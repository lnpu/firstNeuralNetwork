{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondNeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lnpu/firstNeuralNetwork/blob/master/SecondNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdqNtClXpkoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import special, ndimage\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "debug = False\n",
        "\n",
        "def _print(a):\n",
        "  if(debug):\n",
        "    print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFab6x6nqHNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# layer structure\n",
        "class Layer:\n",
        "  def __init__(self, inputNodes, outputNodes, learningRate):\n",
        "    self.iNode = inputNodes\n",
        "    self.oNode = outputNodes\n",
        "    self.lr = learningRate\n",
        "    self.activation_function = lambda x:special.expit(x)\n",
        "    self.weight = np.random.normal(0.0,pow(self.oNode,-0.5),(self.oNode, self.iNode)) #(np.random.rand(self.hNode, self.iNode)-0.5)\n",
        "    _print(self.weight.shape)\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0I5_tOSqK5T",
        "colab_type": "code",
        "outputId": "add21bc5-46fc-4672-a17d-6cf4ce319269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# neural network structure\n",
        "class NN:\n",
        "  # construct neural work struction\n",
        "  def __init__(self):\n",
        "    self.layers = []\n",
        "    pass\n",
        "  # using activation function iterate network once\n",
        "  def train(self, input_list, target_list, epochs=1):\n",
        "    _print('training start')\n",
        "    for epoch in range(epochs):\n",
        "      _print(\"start epoch %d\"%epoch)\n",
        "      inputs = np.array(input_list, ndmin=2, copy=True).T\n",
        "      _print(\"inputs shape is %s\"%(str(inputs.shape)))\n",
        "      targets = np.array(target_list, ndmin=2, copy=True).T\n",
        "      _print(\"targets shape is %s\"%str(targets.shape))\n",
        "      # -> using forward pass compute params \n",
        "      for index,layer in enumerate(self.layers):\n",
        "        _print(\"forward pass %d ...\"%index)\n",
        "        _print(\"weight %d shape is %s\"%(index, str(self.layers[index].weight.shape)))\n",
        "        self.layers[index].inputs = np.dot(self.layers[index].weight, inputs)\n",
        "        # outputs is an input that calculated from activation function\n",
        "        self.layers[index].outputs = self.layers[index].activation_function(self.layers[index].inputs)\n",
        "        _print(self.layers[index].outputs.shape)\n",
        "        inputs = self.layers[index].outputs\n",
        "      # -> use backword pass to update weight\n",
        "      for index,layer in enumerate(self.layers):\n",
        "        # stating at final layer\n",
        "        t = len(self.layers) - 1 - index\n",
        "        #_print(\"backpass pass %d ...\"%t)\n",
        "        # if output layer, using targets - outputs to update errors\n",
        "        if index == 0:\n",
        "          # calculate final layer loss\n",
        "          self.layers[t].errors = targets - self.layers[t].outputs\n",
        "          # calculate and update final layer weight\n",
        "          x = (self.layers[t].errors*self.layers[t].outputs*(1.0-self.layers[t].outputs))\n",
        "          xx = np.dot(x, np.transpose(self.layers[t-1].outputs))\n",
        "          #print(self.layers[t].weight.shape, self.layers[t].lr, x.shape, xx.shape )\n",
        "          self.layers[t].weight += self.layers[t].lr * xx\n",
        "        # if input layer\n",
        "        elif t == 0:\n",
        "          #self.layers[t].errors = np.dot(self.layers[t+1].weight.T, self.layers[t+1].errors)\n",
        "          #x = (self.layers[t].errors*self.layers[t].outputs*(1.0-self.layers[t].outputs))\n",
        "          #xx = np.dot(x, np.transpose(self.layers[t].outputs))\n",
        "          #print(self.layers[t].weight.shape, self.layers[t].lr, x.shape, xx.shape )\n",
        "          #self.layers[t].weight += self.layers[t].lr * xx\n",
        "          pass\n",
        "        # if hidden layer, using next layer to update errors\n",
        "        else:\n",
        "          self.layers[t].errors = np.dot(self.layers[t+1].weight.T, self.layers[t+1].errors)\n",
        "          x = (self.layers[t].errors*self.layers[t].outputs*(1.0-self.layers[t].outputs))\n",
        "          xx = np.dot(x, np.transpose(self.layers[t].outputs))\n",
        "          #print(self.layers[t].weight.shape, self.layers[t].lr,x.shape, xx.shape )\n",
        "          self.layers[t].weight += self.layers[t].lr * xx\n",
        "        pass\n",
        "    pass\n",
        "  def add_layer(self, layer):\n",
        "    self.layers.append(layer)\n",
        "    pass\n",
        "  # predict an input using trained network\n",
        "  def predict(self, inputs_list):\n",
        "    inputs = np.array(inputs_list, ndmin = 2).T\n",
        "    for index,layer in enumerate(self.layers):\n",
        "      self.layers[index].inputs = np.dot(self.layers[index].weight, inputs)\n",
        "      self.layers[index].outputs = self.layers[index].activation_function(self.layers[index].inputs)\n",
        "      inputs = self.layers[index].outputs\n",
        "    return np.argmax(self.layers[len(self.layers)-1].outputs)\n",
        "\n",
        "\n",
        "data_file = open('/content/sample_data/mnist_test.csv', 'r')\n",
        "data_list = data_file.readlines()\n",
        "data_file.close()\n",
        "# training neural network\n",
        "iNode = 784\n",
        "oNode = 10\n",
        "hNode = 100\n",
        "nn = NN()\n",
        "nn.add_layer(Layer(iNode, 100, 0.3))\n",
        "nn.add_layer(Layer(100, 100,   0.3))\n",
        "nn.add_layer(Layer(100, 100,   0.3))\n",
        "nn.add_layer(Layer(100, 100,   0.3))\n",
        "nn.add_layer(Layer(100, 100,   0.3))\n",
        "nn.add_layer(Layer(100, 100,   0.3))\n",
        "nn.add_layer(Layer(100, oNode, 0.3))\n",
        "for line in data_list:\n",
        "  all_values = line.split(',')\n",
        "  correct_label = int(all_values[0])\n",
        "  inputs = (np.asfarray(all_values[1:])/255.0*0.99 + 0.01) #.reshape(28,28)\n",
        "  targets = np.zeros(oNode)+0.01\n",
        "  targets[int(all_values[0])] = 0.99\n",
        "  nn.train(inputs, targets)\n",
        "  pass\n",
        "print('training finished')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkzfK0GAQCXi",
        "colab_type": "code",
        "outputId": "b2352a16-6ea8-48f6-90a8-dac4f3ee2834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# testing nn\n",
        "_tfile = open('/content/sample_data/mnist_test.csv')\n",
        "data_list = _tfile.readlines()\n",
        "_tfile.close()\n",
        "# test neural network use scorecard\n",
        "scorecard = []\n",
        "for line in data_list:\n",
        "  all_values = line.split(',')\n",
        "  correct_label = int(all_values[0])\n",
        "  inputs = (np.asfarray(all_values[1:])/255.0*0.99 + 0.01) #.reshape(28,28)\n",
        "  outputs = nn.predict(inputs)\n",
        "  label = np.argmax(outputs)\n",
        "  #print(\"real: %s, predict: %s\\n\"%(correct_label, label))\n",
        "  scorecard.append(1 if label==correct_label else 0)\n",
        "  pass\n",
        "print(\"Accuracy : %f , testing data size : %d\"%(len([i for i in scorecard if i>0])/len(scorecard), len(data_list)))\n",
        "\n",
        "# testing nn\n",
        "_tfile = open('/content/sample_data/mnist_test.csv')\n",
        "data_list = _tfile.readlines()\n",
        "_tfile.close()\n",
        "all_values = data_list[44].split(',')\n",
        "r = int(all_values[0])\n",
        "p = nn.predict((np.asfarray(all_values[1:])/255*0.99)+0.01)\n",
        "print(\"real %d , predict %d\"%(r,p))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.098000 , testing data size : 10000\n",
            "real 3 , predict 6\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}